{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf99e376",
   "metadata": {},
   "source": [
    "# Plant Health AI Assistant - Runtime with Memory\n",
    "## Overview\n",
    "This notebook demonstrates how to deploy a LangGraph-based plant health analysis system with persistent memory capabilities using AWS Bedrock AgentCore. The system combines multi-agent orchestration with memory storage to provide intelligent plant diagnosis and historical tracking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1771f1",
   "metadata": {},
   "source": [
    "# Key Components\n",
    "1. Multi-Agent LangGraph Workflow\n",
    "Entry Router: Determines if query is for analysis or history retrieval\n",
    "\n",
    "Plant Detection Agent: Identifies plant type and health issues\n",
    "\n",
    "Care Agent: Provides expert treatment advice\n",
    "\n",
    "Web Search Agent: Finds latest research and recommendations\n",
    "\n",
    "Memory Agents: Save and retrieve plant analysis history\n",
    "\n",
    "2. AWS Bedrock AgentCore Memory\n",
    "Persistent storage for plant analysis sessions\n",
    "\n",
    "Actor-based memory isolation (farmer-specific)\n",
    "\n",
    "30-day retention for plant health tracking\n",
    "\n",
    "Conversation-style memory format\n",
    "\n",
    "3. Docker Deployment\n",
    "ARM64 container for AWS optimization\n",
    "\n",
    "Serverless scaling through AgentCore Runtime\n",
    "\n",
    "Production-ready with monitoring and error handling\n",
    "\n",
    "Prerequisites\n",
    "AWS Account with Bedrock AgentCore access\n",
    "\n",
    "Completed MCP Gateway setup (from previous notebook)\n",
    "\n",
    "Docker and AWS CLI configured\n",
    "\n",
    "Python 3.10+ environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66bfec9-e367-484f-ab2d-e99acf267371",
   "metadata": {},
   "source": [
    "# 01. Install dependencies and configure clients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048ca82",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q -r requirements.txt --no-cache-dir\n",
    "\n",
    "print(\"âœ… Requirements installed. Now run the cells below.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081fc289-0c09-48e5-8e94-446ad65b28c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#restart kernel\n",
    "import IPython\n",
    "IPython.Application.instance().kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9ecec-7d81-40e8-b8c6-e9ef083645e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import logging\n",
    "from datetime import datetime\n",
    "from typing import List, TypedDict, Any, Annotated\n",
    "import base64\n",
    "import random\n",
    "import string\n",
    "import shutil\n",
    "import uuid\n",
    "from PIL import Image\n",
    "import io\n",
    "import requests\n",
    "\n",
    "\n",
    "from utils.utils import create_agentcore_role, create_agentcore_mem_role\n",
    "\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    " \n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "from bedrock_agentcore_starter_toolkit.notebook import Runtime\n",
    "\n",
    "# Add this at the top of your notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "# Core clients and variables\n",
    "sts_client = boto3.client('sts')\n",
    "account_id = sts_client.get_caller_identity()[\"Account\"]\n",
    "region = boto3.session.Session().region_name\n",
    "suffix = ''.join(random.choices(string.ascii_lowercase + string.digits, k=8))\n",
    "\n",
    "iam_client = boto3.client('iam')\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d%H%M%S\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3743e5a7-0d44-4489-b569-ddf5377829e0",
   "metadata": {},
   "source": [
    "## Load notebook 01 configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff25cbb7-0e86-47e8-89dc-a5727ec4da41",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    with open('plant_gateway_config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "        \n",
    "    REGION = config['REGION']\n",
    "    GATEWAY_ID = config['GATEWAY_ID']\n",
    "    GATEWAY_URL = config['GATEWAY_URL']\n",
    "    COGNITO_INFO = config['COGNITO_INFO']\n",
    "        \n",
    "    print(f\"Gateway ID: {GATEWAY_ID}\")\n",
    "    print(f\"Gateway URL: {GATEWAY_URL}\")\n",
    "    print(f\"Region: {REGION}\")\n",
    "    print(\"âœ… Configuration loaded successfully!\")\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"âŒ Config file not found. Run the setup notebook first!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e893c5-c57e-48cc-ba04-ca2162cb7736",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup the gateway client\n",
    "gateway_client = GatewayClient(region_name=REGION)\n",
    "\n",
    "# setup memory client\n",
    "memory_client = MemoryClient(region_name=REGION)\n",
    "\n",
    "# Get access token\n",
    "access_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05942fb7-d965-42ec-b789-5f5084e4003b",
   "metadata": {},
   "source": [
    "# Create AgentCore Runtime and AgentCore Memory roles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320ebde8-2633-4a5b-b80d-c5bbf8be2097",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"plant-advisor-agent-langgraph\"\n",
    "agentcore_iam_role = create_agentcore_role(agent_name=agent_name)\n",
    "\n",
    "print(f\"Runtime agent role: {agentcore_iam_role}\")\n",
    "print(\"âœ… Runtime agent role successfully created!\")\n",
    "\n",
    "agentcore_mem_name = \"plant-advisor-mem-langgraph\"\n",
    "MEMORY_ROLE_ARN = create_agentcore_mem_role(agentcore_mem_name)\n",
    "\n",
    "print(f\"Memory agent role: {agentcore_iam_role}\")\n",
    "print(\"âœ… Memory agent role successfully created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550a79e-2f7c-4fa6-88fd-7e177c92416b",
   "metadata": {},
   "source": [
    "# Update configuration with Memory role and name for reuse "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa496d5-dc49-44c3-ac09-1142f4f51ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create unique memory name with timestamp\n",
    "\n",
    "unique_memory_name = f\"PlantHealthAdvisor_{timestamp}\"\n",
    "\n",
    "# Load existing config\n",
    "try:\n",
    "    with open('plant_gateway_config.json', 'r') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # Add memory role ARN\n",
    "    config['MEMORY_ROLE_ARN'] = MEMORY_ROLE_ARN\n",
    "    config['MEMORY_NAME'] = unique_memory_name\n",
    "    \n",
    "    # Write updated config\n",
    "    with open('plant_gateway_config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Added MEMORY_ROLE_ARN to config: {MEMORY_ROLE_ARN}\")\n",
    "    print(f\"   MEMORY_NAME: {unique_memory_name}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to update config: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ee9800-b7e7-4e85-a049-b58e5832c3e6",
   "metadata": {},
   "source": [
    "# Create Memory Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c171408-fdcb-4118-9e4a-7bb02ce1162d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_id = None\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\")\n",
    "logger = logging.getLogger(\"agentcore-memory\")\n",
    "\n",
    "ACTOR_ID = \"user_123\"\n",
    "SESSION_ID = \"plant_analysis_session_001\"  # Reuse same session for continuity\n",
    "\n",
    "#Create Memory Store\n",
    "try:\n",
    "    print(\"Creating Memory...\")\n",
    "    memory = memory_client.create_memory_and_wait(\n",
    "        name=unique_memory_name,\n",
    "        description=\"Plant Health Analysis Memory\",\n",
    "        strategies=[],  # No strategies for short-term memory\n",
    "        event_expiry_days=30,  # Keep plant analyses for 30 days\n",
    "        memory_execution_role_arn=MEMORY_ROLE_ARN,\n",
    "        max_wait=300,\n",
    "        poll_interval=10\n",
    "    )\n",
    "    \n",
    "    memory_id = memory['memoryId']\n",
    "\n",
    "    # Add memory id\n",
    "    config['MEMORY_ID'] = memory_id\n",
    "    \n",
    "    # Write updated config\n",
    "    with open('plant_gateway_config.json', 'w') as f:\n",
    "        json.dump(config, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Memory created successfully with ID: {memory_id}\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    if e.response['Error']['Code'] == 'ValidationException' and \"already exists\" in str(e):\n",
    "        # Memory exists, get its ID\n",
    "        memories = memory_client.list_memories()\n",
    "        memory_id = next((m['id'] for m in memories if m['id'].startswith(memory_name)), None)\n",
    "        print(f\"âœ… Memory already exists. Using existing memory ID: {memory_id}\")\n",
    "    else:\n",
    "        print(f\"âŒ Memory creation error: {e}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ERROR: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00766349-b466-4cc1-9706-d3458aff5a2e",
   "metadata": {},
   "source": [
    "# Langgraph definition and Prep Agent Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc756581-36d1-45ef-b7f1-8611f05ab4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize AgentCore App\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "COGNITO_DOMAIN=config['COGNITO_INFO']['token_endpoint']\n",
    "COGNITO_CLIENT_ID=config['COGNITO_INFO']['client_id']\n",
    "COGNITO_CLIENT_SECRET=config['COGNITO_INFO']['client_secret']\n",
    "\n",
    "print(\"COGNITO_DOMAIN :  \", COGNITO_DOMAIN)\n",
    "print(\"COGNITO_CLIENT_ID :  \", COGNITO_CLIENT_ID)\n",
    "print(\"COGNITO_CLIENT_SECRET :  \", COGNITO_CLIENT_SECRET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ab194-f97a-4129-bb71-8dd5d2b2f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test token generation\n",
    "test_token = gateway_client.get_access_token_for_cognito(config['COGNITO_INFO'])\n",
    "print(f\"âœ… Token test: {test_token[:20]}...\" if test_token else \"âŒ Token failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6258d328-a44a-4250-8b02-085620458b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def parse_mcp_response(result):\n",
    "#     \"\"\"Parse nested MCP response\"\"\"\n",
    "#     try:\n",
    "#         if 'result' in result and 'content' in result['result']:\n",
    "#             content = result['result']['content'][0]['text']\n",
    "#             outer_json = json.loads(content)\n",
    "#             if 'response' in outer_json and 'payload' in outer_json['response']:\n",
    "#                 body = outer_json['response']['payload']['body']\n",
    "#                 return json.loads(body)\n",
    "#         return None\n",
    "#     except Exception as e:\n",
    "#         print(f\"Parse error: {e}\")\n",
    "#         return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1771b1ab-80fd-4d30-be5c-39877528421b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mcp_response(result):\n",
    "    \"\"\"Parse nested MCP response with debugging\"\"\"\n",
    "    try:\n",
    "        # Format 1: Direct Lambda response\n",
    "        if isinstance(result, dict) and 'plant_type' in result:\n",
    "            return {\n",
    "                'plant_name': result.get('plant_type', 'unknown'),\n",
    "                'health_issues': result.get('health_analysis', '')\n",
    "            }\n",
    "        \n",
    "        # Format 2: MCP wrapped response\n",
    "        if 'result' in result and 'content' in result['result']:\n",
    "            content = result['result']['content'][0]['text']\n",
    "            outer_json = json.loads(content)\n",
    "            body_json = json.loads(outer_json['body'])\n",
    "            \n",
    "            # Plant detection response\n",
    "            if 'plant_name' in body_json and 'health_issues' in body_json:\n",
    "                print(f\"âœ… Parsed plant: {body_json.get('plant_name', 'unknown')}\")\n",
    "                return {\n",
    "                    'plant_name': body_json.get('plant_name', 'unknown'),\n",
    "                    'health_issues': body_json.get('health_issues', '')\n",
    "                }\n",
    "            \n",
    "            # Web search response\n",
    "            if 'web_search_results' in body_json:\n",
    "                print(f\"âœ… Parsed web search results\")\n",
    "                return {\n",
    "                    'web_search_results': body_json.get('web_search_results', ''),\n",
    "                    'plant_name': body_json.get('plant_name', 'unknown')\n",
    "                }\n",
    "            \n",
    "            # Plant care response  \n",
    "            if 'expert_advice' in body_json:\n",
    "                print(f\"âœ… Parsed expert advice\")\n",
    "                return {\n",
    "                    'expert_advice': body_json.get('expert_advice', ''),\n",
    "                    'plant_name': body_json.get('plant_name', 'unknown')\n",
    "                }\n",
    "        \n",
    "        print(f\"âŒ Could not parse response format\")\n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Parse error: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff675900-fd3a-4e2b-ac21-9109353ac74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantAnalysisState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    prompt: str           # Add user query\n",
    "    query_type: str       # Add query type: \"analysis\" or \"history\"\n",
    "    image_path: str\n",
    "    image_data: str\n",
    "    plant_detection: dict\n",
    "    health_issues: str\n",
    "    expert_advice: str\n",
    "    web_search_results: str\n",
    "    final_report: str\n",
    "    memory_status: str    # Add memory operation status\n",
    "\n",
    "print(\"âœ… Updated state definition with memory fields\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f95a20c-eac3-482a-a7e8-bff1007eb22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_mcp_tool(tool_name: str, arguments: dict, bearer_token: str):\n",
    "    \"\"\"Generic MCP tool caller\"\"\"\n",
    "    headers = {'Content-Type': 'application/json', 'Authorization': f'Bearer {bearer_token}'}\n",
    "    payload = {\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 3,\n",
    "        \"method\": \"tools/call\",\n",
    "        \"params\": {\"name\": tool_name, \"arguments\": arguments}\n",
    "    }\n",
    "    response = requests.post(GATEWAY_URL, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693967e-930d-41b3-be11-98222ae0d374",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plant_workflow():\n",
    "    \"\"\"Create plant analysis workflow using all three MCP tools + memory\"\"\"\n",
    "    workflow = StateGraph(PlantAnalysisState)\n",
    "    \n",
    "    # Keep ALL your existing functions exactly as they are\n",
    "    def detect_plant(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Plant detection using MCP gateway tool\"\"\"\n",
    "        bearer_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        image_path = state.get('image_path', '')\n",
    "        image_data = state.get('image_data', '')\n",
    "        print(f\"ðŸ” Starting plant detection for: {image_path}\")\n",
    "\n",
    "        try: \n",
    "            if image_data:\n",
    "                print(f\"âœ… Using provided image_data: {len(image_data)} characters\")\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {\n",
    "                    \"image_data\": image_data\n",
    "                }, bearer_token)\n",
    "            elif image_path and not image_path.startswith('s3://') and image_path != \"from_image_data\":\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"âŒ Image file not found: {image_path}\")\n",
    "                    return {\"plant_detection\": {\"plant_type\": \"error\"}, \"health_issues\": \"Image file not found\"}\n",
    "\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    image_bytes = f.read()\n",
    "                    image_data_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                    print(f\"âœ… Image encoded: {len(image_data_encoded)} characters\")\n",
    "\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {\n",
    "                    \"image_data\": image_data_encoded\n",
    "                }, bearer_token)\n",
    "            else:\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {\n",
    "                    \"image_path\": image_path\n",
    "                }, bearer_token)\n",
    "\n",
    "            parsed_result = parse_mcp_response(result)\n",
    "\n",
    "            if parsed_result:\n",
    "                plant_name = parsed_result.get(\"plant_name\", \"unknown\")\n",
    "                health_issues = parsed_result.get(\"health_issues\", \"\")\n",
    "                print(f\"âœ… Plant detected: {plant_name}\")\n",
    "                print(f\"ðŸ“‹ Health status: {health_issues}\")\n",
    "\n",
    "                return {\n",
    "                    \"plant_detection\": {\"plant_type\": plant_name},\n",
    "                    \"health_issues\": health_issues\n",
    "                }\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Plant detection error: {e}\")\n",
    "\n",
    "        return {\"plant_detection\": {\"plant_type\": \"error\"}, \"health_issues\": \"Detection failed\"}\n",
    "\n",
    "    def entry_router(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Route based on query type - history or plant analysis\"\"\"\n",
    "        prompt = state.get(\"prompt\", \"\")\n",
    "        image_data = state.get(\"image_data\", \"\")\n",
    "        image_path = state.get(\"image_path\", \"\")\n",
    "        \n",
    "        # Check for history keywords\n",
    "        if prompt:\n",
    "            history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "            if any(keyword in prompt.lower() for keyword in history_keywords):\n",
    "                return {\"next\": \"retrieve_memory\"}\n",
    "        \n",
    "        # If has image data, go to plant detection\n",
    "        if image_data or image_path:\n",
    "            return {\"next\": \"detect_plant\"}\n",
    "        \n",
    "        return {\"next\": \"END\"}\n",
    "\n",
    "    def analysis_router(state: PlantAnalysisState) -> str:\n",
    "        \"\"\"Route based on plant detection results - your original logic\"\"\"\n",
    "        plant_detection = state.get(\"plant_detection\", {})\n",
    "        plant_name = plant_detection.get(\"plant_type\", \"\").lower()\n",
    "        health_issues = state.get(\"health_issues\", \"\").lower()\n",
    "        \n",
    "        if not plant_name or plant_name == \"error\":\n",
    "            return \"END\"\n",
    "        \n",
    "        # Check for critical issues\n",
    "        critical_keywords = [\"severe\", \"dying\", \"critical\", \"emergency\"]\n",
    "        if any(keyword in health_issues for keyword in critical_keywords):\n",
    "            return \"urgent_consultation\"\n",
    "        \n",
    "        return \"expert_consultation\"\n",
    "\n",
    "    # Keep all your existing functions unchanged\n",
    "    def plant_care_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Plant care using MCP gateway tool\"\"\"\n",
    "        bearer_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        plant_info = state.get('plant_detection', {})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"ðŸŒ± Getting care advice for: {plant_name}\")\n",
    "        print(f\"ðŸ“‹ Health status: {health_status}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-care-target___plant_care_tool\", {\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result and 'expert_advice' in parsed_result:\n",
    "                advice = parsed_result['expert_advice']\n",
    "                print(f\"âœ… Care advice received ({len(advice)} chars)\")\n",
    "                return {'expert_advice': advice}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Plant care error: {e}\")\n",
    "        \n",
    "        return {'expert_advice': 'Plant care advice unavailable'}\n",
    "\n",
    "    def web_search_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Web search using MCP gateway tool\"\"\"\n",
    "        bearer_token = gateway_client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        plant_info = state.get('plant_detection', {})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"ðŸ” Web searching for: {plant_name}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-web-search-target___plant_web_search_tool\", {\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result:\n",
    "                search_results = parsed_result.get('web_search_results', str(parsed_result))\n",
    "                print(f\"âœ… Web search completed ({len(search_results)} chars)\")\n",
    "                return {'web_search_results': search_results}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Web search error: {e}\")\n",
    "        \n",
    "        return {'web_search_results': 'Web search unavailable'}\n",
    "\n",
    "    def expert_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Expert consultation with fallback to web search\"\"\"\n",
    "        care_result = plant_care_agent(state)\n",
    "        \n",
    "        if care_result.get('expert_advice') and 'unavailable' not in care_result.get('expert_advice', ''):\n",
    "            return care_result\n",
    "        \n",
    "        web_result = web_search_agent(state)\n",
    "        return {\n",
    "            'expert_advice': web_result.get('web_search_results', 'No advice available'),\n",
    "            'web_search_results': web_result.get('web_search_results', '')\n",
    "        }\n",
    "\n",
    "    def urgent_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Urgent consultation - uses both care and web search\"\"\"\n",
    "        care_result = plant_care_agent(state)\n",
    "        web_result = web_search_agent(state)\n",
    "        \n",
    "        expert_advice = care_result.get('expert_advice', '')\n",
    "        web_search_results = web_result.get('web_search_results', '')\n",
    "        \n",
    "        combined_advice = f\"\"\"**Expert Care Advice:**\n",
    "{expert_advice}\n",
    "\n",
    "**Additional Web Research:**\n",
    "{web_search_results}\"\"\"\n",
    "        \n",
    "        return {\n",
    "            'expert_advice': combined_advice,\n",
    "            'web_search_results': web_search_results\n",
    "        }\n",
    "    \n",
    "    def write_report(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Generate final report\"\"\"\n",
    "        plant_info = state.get(\"plant_detection\", {})\n",
    "        health_issues = state.get(\"health_issues\", \"\")\n",
    "        expert_advice = state.get(\"expert_advice\", \"\")\n",
    "        web_search_results = state.get(\"web_search_results\", \"\")\n",
    "        \n",
    "        report = f\"\"\"# Plant Analysis Report\n",
    "\n",
    "## Detection Results\n",
    "- Plant Type: {plant_info.get('plant_type', 'Unknown')}\n",
    "- Health Assessment: {health_issues}\n",
    "\n",
    "## Expert Recommendations\n",
    "{expert_advice}\n",
    "\n",
    "## Analysis Method\n",
    "- Source: MCP Gateway Tools\n",
    "- Detection Tool: plant-detection-target___plant_detection_tool\n",
    "- Care Tool: plant-care-target___plant_care_tool\n",
    "- Search Tool: plant-web-search-target___plant_web_search_tool\n",
    "\"\"\"\n",
    "        \n",
    "        return {\"final_report\": report}\n",
    "    \n",
    "    # Memory functions\n",
    "    def retrieve_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Retrieve plant analysis history from memory\"\"\"\n",
    "        try:\n",
    "            \n",
    "            events = memory_client.list_events(\n",
    "                memory_id=memory_id,\n",
    "                actor_id=ACTOR_ID,\n",
    "                session_id=SESSION_ID,\n",
    "                max_results=10\n",
    "            )\n",
    "            \n",
    "            if events:\n",
    "                history_summary = \"# Plant Analysis History\\n\\n\"\n",
    "                for i, event in enumerate(events, 1):\n",
    "                    history_summary += f\"{i}. {event}\\n\"\n",
    "            else:\n",
    "                history_summary = \"# Plant Analysis History\\n\\nNo previous analyses found.\"\n",
    "            \n",
    "            return {\n",
    "                \"final_report\": history_summary,\n",
    "                \"memory_status\": \"retrieved\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"final_report\": f\"# Memory Error\\n\\nCould not retrieve history: {str(e)}\",\n",
    "                \"memory_status\": \"error\"\n",
    "            }\n",
    "\n",
    "    def save_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        \"\"\"Save plant analysis to memory after report generation\"\"\"\n",
    "        try:\n",
    "            plant_info = state.get(\"plant_detection\", {})\n",
    "            health_issues = state.get(\"health_issues\", \"\")\n",
    "            expert_advice = state.get(\"expert_advice\", \"\")\n",
    "            \n",
    "            conversation = [\n",
    "                (f\"Plant analysis for {plant_info.get('plant_type', 'unknown plant')}\", \"USER\"),\n",
    "                (f\"Plant: {plant_info.get('plant_type')}\\nHealth: {health_issues}\\nAdvice: {expert_advice}\", \"ASSISTANT\")\n",
    "            ]\n",
    "            \n",
    "            memory_client.save_conversation(\n",
    "                memory_id=memory_id,\n",
    "                actor_id=ACTOR_ID,\n",
    "                session_id=SESSION_ID,\n",
    "                messages=conversation\n",
    "            )\n",
    "            \n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + f\"\\n\\n*Analysis saved to memory for future reference*\"\n",
    "            \n",
    "            return {\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": \"saved\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + f\"\\n\\n*Memory save failed: {str(e)}*\"\n",
    "            return {\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": f\"save_failed: {str(e)}\"\n",
    "            }\n",
    "    \n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"entry_router\", entry_router)              # NEW: Entry router\n",
    "    workflow.add_node(\"detect_plant\", detect_plant)\n",
    "    workflow.add_node(\"urgent_consultation\", urgent_consultation_agent)\n",
    "    workflow.add_node(\"expert_consultation\", expert_consultation_agent)\n",
    "    workflow.add_node(\"write_report\", write_report)\n",
    "    workflow.add_node(\"retrieve_memory\", retrieve_memory_agent)\n",
    "    workflow.add_node(\"save_memory\", save_memory_agent)\n",
    "    \n",
    "    # Build workflow with TWO routers\n",
    "    workflow.set_entry_point(\"entry_router\")  # Start with entry router\n",
    "\n",
    "    # Then use it directly in conditional edges\n",
    "    workflow.add_conditional_edges(\n",
    "        \"entry_router\",\n",
    "        lambda state: state[\"next\"],  # âŒ This looks for \"next\" in workflow state\n",
    "        {\n",
    "            \"detect_plant\": \"detect_plant\",\n",
    "            \"retrieve_memory\": \"retrieve_memory\",\n",
    "            \"END\": END\n",
    "        }\n",
    "    )\n",
    "    # Analysis router edges (after plant detection)\n",
    "    workflow.add_conditional_edges(\n",
    "        \"detect_plant\",\n",
    "        analysis_router,  # Your original router logic\n",
    "        {\n",
    "            \"urgent_consultation\": \"urgent_consultation\",\n",
    "            \"expert_consultation\": \"expert_consultation\",\n",
    "            \"END\": END\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Analysis completion paths\n",
    "    workflow.add_edge(\"expert_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"urgent_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"write_report\", \"save_memory\")\n",
    "    workflow.add_edge(\"save_memory\", END)\n",
    "    \n",
    "    # History path\n",
    "    workflow.add_edge(\"retrieve_memory\", END)\n",
    "    \n",
    "    return workflow.compile(checkpointer=MemorySaver())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e731794-8d84-4ed5-a522-1505d64014fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    \"\"\"AgentCore entrypoint for LangGraph MCP workflow with memory support\"\"\"\n",
    "    # Truncate image_data for cleaner logging\n",
    "    log_payload = payload.copy()\n",
    "    if 'image_data' in log_payload and log_payload['image_data']:\n",
    "        log_payload['image_data'] = f\"{log_payload['image_data'][:50]}... ({len(log_payload['image_data'])} chars)\"\n",
    "    \n",
    "    print(f\"ðŸ“¥ Received payload: {log_payload}\")\n",
    "    \n",
    "    prompt = payload.get(\"prompt\", \"\")\n",
    "    image_path = payload.get(\"image_path\", \"\")\n",
    "    image_data = payload.get(\"image_data\", \"\")\n",
    "    \n",
    "    # Check if this is a history query\n",
    "    history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "    is_history_query = any(keyword in prompt.lower() for keyword in history_keywords) if prompt else False\n",
    "    \n",
    "    # Only require image for non-history queries\n",
    "    if not is_history_query and not image_path and not image_data:\n",
    "        return {\"error\": \"No image_path or image_data provided for plant analysis\", \"status\": \"failed\"}\n",
    "    \n",
    "    # Initialize state with all required fields\n",
    "    initial_state = {\n",
    "        \"messages\": [],\n",
    "        \"prompt\": prompt,                                      # ADD: For history detection\n",
    "        \"image_path\": image_path or \"from_image_data\",\n",
    "        \"image_data\": image_data,\n",
    "        \"plant_detection\": {},\n",
    "        \"health_issues\": \"\",\n",
    "        \"expert_advice\": \"\",\n",
    "        \"web_search_results\": \"\",\n",
    "        \"final_report\": \"\",\n",
    "        \"memory_status\": \"\"                                    # ADD: For memory operations\n",
    "    }\n",
    "    \n",
    "    config = {\"configurable\": {\"thread_id\": f\"agentcore_{random.randint(1000, 9999)}\"}}\n",
    "    \n",
    "    try:\n",
    "        final_state = langgraph_workflow.invoke(initial_state, config)\n",
    "        \n",
    "        return {\n",
    "            \"plant_type\": final_state.get('plant_detection', {}).get('plant_type', 'Unknown'),\n",
    "            \"health_issues\": final_state.get('health_issues', ''),\n",
    "            \"expert_advice\": final_state.get('expert_advice', ''),\n",
    "            \"web_search_results\": final_state.get('web_search_results', ''),\n",
    "            \"final_report\": final_state.get('final_report', ''),\n",
    "            \"memory_status\": final_state.get('memory_status', ''),    # ADD: Return memory status\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Workflow error: {str(e)}\")\n",
    "        return {\"error\": str(e), \"status\": \"failed\"}\n",
    "\n",
    "print(\"âœ… LangGraph MCP Workflow with Memory created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f97ff0-a3b4-4254-a50d-87fe280d7382",
   "metadata": {},
   "source": [
    "# Visualize LangGraph workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451984a7-f9e7-45be-b505-22475ad6830f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize the workflow\n",
    "langgraph_workflow = create_plant_workflow()\n",
    "\n",
    "if langgraph_workflow is None:\n",
    "    print(\"âŒ Workflow creation failed!\")\n",
    "else:\n",
    "    print(\"âœ… LangGraph MCP Workflow created with all tools\")\n",
    "\n",
    "def visualize_enhanced_workflow():\n",
    "    \"\"\"Generate and display enhanced workflow graph\"\"\"\n",
    "    try:\n",
    "        # Check if workflow exists\n",
    "        if langgraph_workflow is None:\n",
    "            print(\"âŒ Cannot visualize: workflow is None\")\n",
    "            return\n",
    "            \n",
    "        from IPython.display import Image, display\n",
    "        from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod\n",
    "        \n",
    "        # Use the already created workflow\n",
    "        display(Image(langgraph_workflow.get_graph().draw_mermaid_png(\n",
    "            curve_style=CurveStyle.LINEAR,\n",
    "            wrap_label_n_words=6,\n",
    "            draw_method=MermaidDrawMethod.PYPPETEER,\n",
    "            background_color=\"white\",\n",
    "            padding=25,\n",
    "            output_file_path=\"enhanced_plant_workflow.png\"\n",
    "        )))\n",
    "        \n",
    "        print(\"âœ… Workflow graph saved as 'enhanced_plant_workflow.png'\")\n",
    "        print(\"ðŸŽ¯ Shows: Detection â†’ Router â†’ [Urgent/Expert] Consultation â†’ Report\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Graph generation failed: {e}\")\n",
    "\n",
    "# Generate visualization AFTER workflow is created\n",
    "if langgraph_workflow is not None:\n",
    "    print(\"ðŸŽ¨ Generating workflow visualization...\")\n",
    "    visualize_enhanced_workflow()\n",
    "else:\n",
    "    print(\"âŒ Skipping visualization - workflow creation failed\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43aed9a4-8152-4a19-b1d2-7a1b20989140",
   "metadata": {},
   "source": [
    "# Test Langgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fc40e1-887e-41ee-95c9-7ed23b463086",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='./Image/sweet_potato_leaf.png'\n",
    "\n",
    "try:\n",
    "    print('ðŸš€ Testing Plant Agent LOCAL...')\n",
    "    \n",
    "    # Read and encode the image file\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "        base64_data = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        print(f\"âœ… Image encoded: {len(base64_data)} characters\")\n",
    "    \n",
    "    # Test payload\n",
    "    test_payload = {\n",
    "        'prompt': 'Analyze my plant',\n",
    "        'image_data': base64_data\n",
    "    }\n",
    "    \n",
    "    response = invoke(test_payload)\n",
    "    print(f'âœ… Agent invocation successful!')\n",
    "    print(f'ðŸ“ Response Content Type: {response.get(\"contentType\")}')\n",
    "    \n",
    "    # Process response - FULL OUTPUT\n",
    "    if response.get(\"contentType\") == \"application/json\":\n",
    "        content = []\n",
    "        for chunk in response.get(\"response\", []):\n",
    "            #content.append(chunk.decode('utf-8'))\n",
    "            content.append(chunk)\n",
    "        result = json.loads(''.join(content))\n",
    "\n",
    "        print(response)\n",
    "        \n",
    "        print(f\"\\nðŸŒ± COMPLETE Plant Analysis Results:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ Plant Type: {result.get('plant_type', 'Unknown')}\")\n",
    "        \n",
    "        print(f\"\\nðŸ” Health Assessment:\")\n",
    "        print(result.get('health_issues', 'None'))\n",
    "        \n",
    "        print(f\"\\nðŸ‘¨â€âš•ï¸ Expert Advice:\")\n",
    "        print(result.get('expert_advice', 'No advice available'))\n",
    "        \n",
    "        if result.get('web_search_results'):\n",
    "            print(f\"\\nðŸ” Web Search Results:\")\n",
    "            print(result.get('web_search_results'))\n",
    "        \n",
    "        print(f\"\\nðŸ“„ Final Report:\")\n",
    "        print(result.get('final_report', 'No report available'))\n",
    "        \n",
    "        print(f\"\\nâœ… Status: {result.get('status', 'Unknown')}\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(f\"Raw response: {response}\")\n",
    "    \n",
    "    print('\\nðŸŽ‰ Plant Agent Runtime working perfectly with real image data!')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'âŒ Agent invocation failed: {e}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59acfca-1e6e-426c-8de2-bfc642d0af12",
   "metadata": {},
   "source": [
    "# Prep Runtime agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e88ac8f-6827-4b5b-8a4d-fbad5a87feb2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create project folder\n",
    "project_folder = \"plant_agent_runtime\"\n",
    "os.makedirs(project_folder, exist_ok=True)\n",
    "\n",
    "print(f\"âœ… Created folder: {project_folder}\")\n",
    "\n",
    "# Create __init__.py file\n",
    "init_content = '''\"\"\"\n",
    "Plant Analysis Agent - LangGraph MCP Workflow with Memory\n",
    "\"\"\"\n",
    "\n",
    "__version__ = \"1.0.0\"\n",
    "__author__ = \"Plant Health Team\"\n",
    "'''\n",
    "\n",
    "with open(f\"{project_folder}/__init__.py\", 'w') as f:\n",
    "    f.write(init_content)\n",
    "\n",
    "print(\"âœ… Created __init__.py\")\n",
    "\n",
    "# Copy requirements.txt\n",
    "files_to_copy = ['requirements.txt']\n",
    "\n",
    "for file_name in files_to_copy:\n",
    "    if os.path.exists(file_name):\n",
    "        shutil.copy(file_name, f\"{project_folder}/{file_name}\")\n",
    "        print(f\"âœ… Copied: {file_name}\")\n",
    "    else:\n",
    "        print(f\"âŒ Not found: {file_name}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea250a23-dd5f-4964-892b-be4cb109d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('plant_gateway_config.json', 'r') as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "workflow_code = f'''\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import logging\n",
    "import boto3\n",
    "import string\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import json\n",
    "from typing import List, TypedDict, Any\n",
    "from langchain_core.messages import AnyMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from typing import Annotated\n",
    "from bedrock_agentcore.runtime import BedrockAgentCoreApp\n",
    "from bedrock_agentcore.memory import MemoryClient\n",
    "from botocore.exceptions import ClientError\n",
    "import random\n",
    "import nest_asyncio\n",
    "import base64\n",
    "\n",
    "from bedrock_agentcore_starter_toolkit.operations.gateway.client import GatewayClient\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "app = BedrockAgentCoreApp()\n",
    "\n",
    "# Fixed configuration - no quotes around dict\n",
    "COGNITO_INFO = {config['COGNITO_INFO']}\n",
    "REGION = '{config.get('REGION')}'\n",
    "GATEWAY_ID = '{config['GATEWAY_ID']}'\n",
    "GATEWAY_URL = '{config['GATEWAY_URL']}'\n",
    "MEMORY_ID = '{memory_id}'\n",
    "MEMORY_ROLE_ARN = '{config['MEMORY_ROLE_ARN']}'\n",
    "   \n",
    "client = GatewayClient(region_name=REGION)    \n",
    "memory_client = MemoryClient(region_name=REGION)\n",
    "\n",
    "ACTOR_ID = \"user_123\"\n",
    "SESSION_ID = \"plant_analysis_session_001\"\n",
    "\n",
    "class PlantAnalysisState(TypedDict):\n",
    "    messages: Annotated[List[AnyMessage], add_messages]\n",
    "    prompt: str           \n",
    "    query_type: str       \n",
    "    image_path: str\n",
    "    image_data: str\n",
    "    plant_detection: dict\n",
    "    health_issues: str\n",
    "    expert_advice: str\n",
    "    recommended_fertilizer: str\n",
    "    web_search_results: str\n",
    "    final_report: str\n",
    "    memory_status: str    \n",
    "    order_status: str\n",
    "    live_session_url: str\n",
    "    message: str\n",
    "\n",
    "def call_mcp_tool(tool_name: str, arguments: dict, bearer_token: str):\n",
    "    headers = {{'Content-Type': 'application/json', 'Authorization': f'Bearer {{bearer_token}}'}}\n",
    "    payload = {{\n",
    "        \"jsonrpc\": \"2.0\",\n",
    "        \"id\": 3,\n",
    "        \"method\": \"tools/call\",\n",
    "        \"params\": {{\"name\": tool_name, \"arguments\": arguments}}\n",
    "    }}\n",
    "    response = requests.post(GATEWAY_URL, headers=headers, json=payload)\n",
    "    return response.json()\n",
    "\n",
    "def parse_mcp_response(result):\n",
    "    try:\n",
    "        # Format 1: Direct Lambda response\n",
    "        if isinstance(result, dict) and 'plant_type' in result:\n",
    "            return {{\n",
    "                'plant_name': result.get('plant_type', 'unknown'),\n",
    "                'health_issues': result.get('health_analysis', '')\n",
    "            }}\n",
    "        \n",
    "        # Format 2: MCP wrapped response\n",
    "        if 'result' in result and 'content' in result['result']:\n",
    "            content = result['result']['content'][0]['text']\n",
    "            outer_json = json.loads(content)\n",
    "            body_json = json.loads(outer_json['body'])  # Double parsing needed\n",
    "            \n",
    "            # Plant detection response\n",
    "            if 'plant_name' in body_json and 'health_issues' in body_json:\n",
    "                return {{\n",
    "                    'plant_name': body_json.get('plant_name', 'unknown'),\n",
    "                    'health_issues': body_json.get('health_issues', '')\n",
    "                }}\n",
    "            \n",
    "            # Web search response\n",
    "            if 'web_search_results' in body_json:\n",
    "                return {{\n",
    "                    'web_search_results': body_json.get('web_search_results', ''),\n",
    "                    'plant_name': body_json.get('plant_name', 'unknown')\n",
    "                }}\n",
    "            \n",
    "            # Plant care response  \n",
    "            if 'expert_advice' in body_json:\n",
    "                return {{\n",
    "                    'expert_advice': body_json.get('expert_advice', ''),\n",
    "                    'plant_name': body_json.get('plant_name', 'unknown')\n",
    "                }}\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Parse error: {{str(e)}}\")  # Fixed f-string\n",
    "        return None\n",
    "\n",
    "\n",
    "def create_plant_workflow():\n",
    "    workflow = StateGraph(PlantAnalysisState)\n",
    "    \n",
    "    def detect_plant(state: PlantAnalysisState) -> dict:\n",
    "        try:\n",
    "            bearer_token = client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        except Exception as token_error:\n",
    "            raise token_error\n",
    "        \n",
    "        image_data = state.get('image_data', '')\n",
    "        image_path = state.get('image_path', '')  # Fixed: Added missing variable\n",
    "\n",
    "        try: \n",
    "            if image_data:\n",
    "                print(f\"âœ… Using provided image_data: {{len(image_data)}} characters\")\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {{\n",
    "                    \"image_data\": image_data\n",
    "                }}, bearer_token)\n",
    "            elif image_path and not image_path.startswith('s3://') and image_path != \"from_image_data\":\n",
    "                if not os.path.exists(image_path):\n",
    "                    print(f\"âŒ Image file not found: {{image_path}}\")\n",
    "                    return {{\"plant_detection\": {{\"plant_type\": \"error\"}}, \"health_issues\": \"Image file not found\"}}\n",
    "\n",
    "                with open(image_path, 'rb') as f:\n",
    "                    image_bytes = f.read()\n",
    "                    image_data_encoded = base64.b64encode(image_bytes).decode('utf-8')\n",
    "                    print(f\"âœ… Image encoded: {{len(image_data_encoded)}} characters\")\n",
    "\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {{\n",
    "                    \"image_data\": image_data_encoded\n",
    "                }}, bearer_token)\n",
    "            else:\n",
    "                result = call_mcp_tool(\"plant-detection-target___plant_detection_tool\", {{\n",
    "                    \"image_path\": image_path\n",
    "                }}, bearer_token)\n",
    "\n",
    "            parsed_result = parse_mcp_response(result)\n",
    "\n",
    "            if parsed_result:\n",
    "                plant_name = parsed_result.get(\"plant_name\", \"unknown\")\n",
    "                health_issues = parsed_result.get(\"health_issues\", \"\")\n",
    "                print(f\"âœ… Plant detected: {{plant_name}}\")\n",
    "                print(f\"ðŸ“‹ Health status: {{health_issues}}\")\n",
    "\n",
    "                return {{\n",
    "                    \"plant_detection\": {{\"plant_type\": plant_name}},\n",
    "                    \"health_issues\": health_issues\n",
    "                }}\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Plant detection error: {{e}}\")\n",
    "\n",
    "        return {{\"plant_detection\": {{\"plant_type\": \"error\"}}, \"health_issues\": \"Detection failed\"}}\n",
    "\n",
    "    def entry_router(state: PlantAnalysisState) -> dict:\n",
    "        prompt = state.get(\"prompt\", \"\")\n",
    "        image_data = state.get(\"image_data\", \"\")\n",
    "        image_path = state.get(\"image_path\", \"\")\n",
    "        \n",
    "        if prompt:\n",
    "            history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "            if any(keyword in prompt.lower() for keyword in history_keywords):\n",
    "                return {{\"next\": \"retrieve_memory\"}}\n",
    "        \n",
    "        if image_data or image_path:\n",
    "            return {{\"next\": \"detect_plant\"}}\n",
    "        \n",
    "        return {{\"next\": \"END\"}}\n",
    "        \n",
    "    def analysis_router(state: PlantAnalysisState) -> str:\n",
    "        plant_detection = state.get(\"plant_detection\", {{}})\n",
    "        plant_name = plant_detection.get(\"plant_type\", \"\").lower()\n",
    "        health_issues = state.get(\"health_issues\", \"\").lower()\n",
    "        \n",
    "        if not plant_name or plant_name == \"error\":\n",
    "            return \"END\"\n",
    "        \n",
    "        critical_keywords = [\"severe\", \"dying\", \"critical\", \"emergency\"]\n",
    "        if any(keyword in health_issues for keyword in critical_keywords):\n",
    "            return \"urgent_consultation\"\n",
    "        \n",
    "        return \"expert_consultation\"\n",
    "\n",
    "    def plant_care_agent(state: PlantAnalysisState) -> dict:\n",
    "        bearer_token = client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        plant_info = state.get('plant_detection', {{}})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"ðŸŒ± Getting care advice for: {{plant_name}}\")\n",
    "        print(f\"ðŸ“‹ Health status: {{health_status}}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-care-target___plant_care_tool\", {{\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }}, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result and 'expert_advice' in parsed_result:\n",
    "                advice = parsed_result['expert_advice']\n",
    "                print(f\"âœ… Care advice received ({{len(advice)}} chars)\")\n",
    "                fertilizer = parsed_result.get('recommended_fertilizer', 'All Purpose Plant Fertilizer')\n",
    "                return {{'expert_advice': advice, 'recommended_fertilizer': fertilizer}}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Plant care error: {{e}}\")\n",
    "        \n",
    "        return {{'expert_advice': 'Plant care advice unavailable'}}\n",
    "\n",
    "    def web_search_agent(state: PlantAnalysisState) -> dict:\n",
    "        bearer_token = client.get_access_token_for_cognito(COGNITO_INFO)\n",
    "        plant_info = state.get('plant_detection', {{}})\n",
    "        health_status = state.get('health_issues', '')\n",
    "        plant_name = plant_info.get('plant_type', 'unknown plant')\n",
    "        \n",
    "        print(f\"ðŸ” Web searching for: {{plant_name}}\")\n",
    "        \n",
    "        try:\n",
    "            result = call_mcp_tool(\"plant-web-search-target___plant_web_search_tool\", {{\n",
    "                \"plant_name\": plant_name,\n",
    "                \"health_status\": health_status\n",
    "            }}, bearer_token)\n",
    "            \n",
    "            parsed_result = parse_mcp_response(result)\n",
    "            \n",
    "            if parsed_result:\n",
    "                search_results = parsed_result.get('web_search_results', str(parsed_result))\n",
    "                print(f\"âœ… Web search completed ({{len(search_results)}} chars)\")\n",
    "                return {{'web_search_results': search_results}}\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Web search error: {{e}}\")\n",
    "        \n",
    "        return {{'web_search_results': 'Web search unavailable'}}\n",
    "\n",
    "    def expert_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        care_result = plant_care_agent(state)\n",
    "        \n",
    "        if care_result.get('expert_advice') and 'unavailable' not in care_result.get('expert_advice', ''):\n",
    "            return care_result\n",
    "        \n",
    "        web_result = web_search_agent(state)\n",
    "        return {{\n",
    "            'expert_advice': web_result.get('web_search_results', 'No advice available'),\n",
    "            'web_search_results': web_result.get('web_search_results', '')\n",
    "        }}\n",
    "\n",
    "    def urgent_consultation_agent(state: PlantAnalysisState) -> dict:\n",
    "        care_result = plant_care_agent(state)\n",
    "        web_result = web_search_agent(state)\n",
    "        \n",
    "        expert_advice = care_result.get('expert_advice', '')\n",
    "        web_search_results = web_result.get('web_search_results', '')\n",
    "        \n",
    "        combined_advice = f\"\"\"**Expert Care Advice:**\n",
    "{{expert_advice}}\n",
    "\n",
    "**Additional Web Research:**\n",
    "{{web_search_results}}\"\"\"\n",
    "        \n",
    "        return {{\n",
    "            'expert_advice': combined_advice,\n",
    "            'web_search_results': web_search_results\n",
    "        }}\n",
    "    \n",
    "    def write_report(state: PlantAnalysisState) -> dict:\n",
    "        plant_info = state.get(\"plant_detection\", {{}})\n",
    "        health_issues = state.get(\"health_issues\", \"\")\n",
    "        expert_advice = state.get(\"expert_advice\", \"\")\n",
    "        \n",
    "        report = f\"\"\"# Plant Analysis Report\n",
    "\n",
    "## Detection Results\n",
    "- Plant Type: {{plant_info.get('plant_type', 'Unknown')}}\n",
    "- Health Assessment: {{health_issues}}\n",
    "\n",
    "## Expert Recommendations\n",
    "{{expert_advice}}\n",
    "\"\"\"\n",
    "        \n",
    "        return {{\"final_report\": report}}\n",
    "    \n",
    "    def retrieve_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        try:\n",
    "            events = memory_client.list_events(\n",
    "                memory_id=MEMORY_ID,\n",
    "                actor_id=ACTOR_ID,\n",
    "                session_id=SESSION_ID,\n",
    "                max_results=10\n",
    "            )\n",
    "            \n",
    "            if events:\n",
    "                history_summary = \"# Plant Analysis History\\\\n\\\\n\"\n",
    "                for i, event in enumerate(events, 1):\n",
    "                    history_summary += f\"{{i}}. {{event}}\\\\n\"\n",
    "            else:\n",
    "                history_summary = \"# Plant Analysis History\\\\n\\\\nNo previous analyses found.\"\n",
    "            \n",
    "            return {{\n",
    "                \"final_report\": history_summary,\n",
    "                \"memory_status\": \"retrieved\"\n",
    "            }}\n",
    "        except Exception as e:\n",
    "            return {{\n",
    "                \"final_report\": f\"# Memory Error\\\\n\\\\nCould not retrieve history: {{str(e)}}\",\n",
    "                \"memory_status\": \"error\"\n",
    "            }}\n",
    "\n",
    "    \n",
    "    def save_memory_agent(state: PlantAnalysisState) -> dict:\n",
    "        try:\n",
    "            plant_info = state.get(\"plant_detection\", {{}})\n",
    "            health_issues = state.get(\"health_issues\", \"\")\n",
    "            expert_advice = state.get(\"expert_advice\", \"\")\n",
    "            \n",
    "            conversation = [\n",
    "                (f\"Plant analysis for {{plant_info.get('plant_type', 'unknown plant')}}\", \"USER\"),\n",
    "                (f\"Plant: {{plant_info.get('plant_type')}}\\\\nHealth: {{health_issues}}\\\\nAdvice: {{expert_advice}}\", \"ASSISTANT\")\n",
    "            ]\n",
    "            \n",
    "            memory_client.save_conversation(\n",
    "                memory_id=MEMORY_ID,\n",
    "                actor_id=ACTOR_ID,\n",
    "                session_id=SESSION_ID,\n",
    "                messages=conversation\n",
    "            )\n",
    "            \n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + \"\\\\n\\\\n*Analysis saved to memory for future reference*\"\n",
    "            \n",
    "            return {{\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": \"saved\"\n",
    "            }}\n",
    "        except Exception as e:\n",
    "            current_report = state.get(\"final_report\", \"\")\n",
    "            enhanced_report = current_report + f\"\\\\n\\\\n*Memory save failed: {{str(e)}}*\"\n",
    "            return {{\n",
    "                \"final_report\": enhanced_report,\n",
    "                \"memory_status\": f\"save_failed: {{str(e)}}\"\n",
    "            }}\n",
    "    \n",
    "    # Add all nodes\n",
    "    workflow.add_node(\"entry_router\", entry_router)\n",
    "    workflow.add_node(\"detect_plant\", detect_plant)\n",
    "    workflow.add_node(\"urgent_consultation\", urgent_consultation_agent)\n",
    "    workflow.add_node(\"expert_consultation\", expert_consultation_agent)\n",
    "    workflow.add_node(\"write_report\", write_report)\n",
    "    workflow.add_node(\"retrieve_memory\", retrieve_memory_agent)\n",
    "    workflow.add_node(\"save_memory\", save_memory_agent)\n",
    "    \n",
    "    workflow.set_entry_point(\"entry_router\")\n",
    "\n",
    "    workflow.add_conditional_edges(\n",
    "        \"entry_router\",\n",
    "        lambda state: state[\"next\"],\n",
    "        {{\n",
    "            \"detect_plant\": \"detect_plant\",\n",
    "            \"retrieve_memory\": \"retrieve_memory\",\n",
    "            \"END\": END\n",
    "        }}\n",
    "    )\n",
    "    \n",
    "    workflow.add_conditional_edges(\n",
    "        \"detect_plant\",\n",
    "        analysis_router,\n",
    "        {{\n",
    "            \"urgent_consultation\": \"urgent_consultation\",\n",
    "            \"expert_consultation\": \"expert_consultation\",\n",
    "            \"END\": END\n",
    "        }}\n",
    "    )\n",
    "    \n",
    "    workflow.add_edge(\"expert_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"urgent_consultation\", \"write_report\")\n",
    "    workflow.add_edge(\"write_report\", \"save_memory\")\n",
    "    workflow.add_edge(\"save_memory\", END)\n",
    "    workflow.add_edge(\"retrieve_memory\", END)\n",
    "    \n",
    "    return workflow.compile(checkpointer=MemorySaver())   \n",
    "\n",
    "langgraph_workflow = create_plant_workflow()\n",
    "\n",
    "@app.entrypoint\n",
    "def invoke(payload):\n",
    "    log_payload = payload.copy()\n",
    "    if 'image_data' in log_payload and log_payload['image_data']:\n",
    "        log_payload['image_data'] = f\"{{log_payload['image_data'][:50]}}... ({{len(log_payload['image_data'])}} chars)\"\n",
    "    \n",
    "    print(f\"ðŸ“¥ Received payload: {{log_payload}}\")\n",
    "    \n",
    "    prompt = payload.get(\"prompt\", \"\")\n",
    "    image_path = payload.get(\"image_path\", \"\")\n",
    "    image_data = payload.get(\"image_data\", \"\")\n",
    "    \n",
    "    history_keywords = [\"show me\", \"previous\", \"compare\", \"history\", \"analyses\", \"month\", \"last time\"]\n",
    "    is_history_query = any(keyword in prompt.lower() for keyword in history_keywords) if prompt else False\n",
    "    \n",
    "    if not is_history_query and not image_path and not image_data:\n",
    "        return {{\"error\": \"No image_path or image_data provided for plant analysis\", \"status\": \"failed\"}}\n",
    "    \n",
    "    initial_state = {{\n",
    "        \"messages\": [],\n",
    "        \"prompt\": prompt,\n",
    "        \"query_type\": \"history\" if is_history_query else \"analysis\",\n",
    "        \"image_path\": image_path or \"from_image_data\",\n",
    "        \"image_data\": image_data,\n",
    "        \"plant_detection\": {{}},\n",
    "        \"health_issues\": \"\",\n",
    "        \"expert_advice\": \"\",\n",
    "        \"recommended_fertilizer\": \"\",\n",
    "        \"web_search_results\": \"\",\n",
    "        \"final_report\": \"\",\n",
    "        \"memory_status\": \"\",\n",
    "        \"order_status\": \"\",\n",
    "        \"live_session_url\": \"\",\n",
    "        \"message\": \"\"\n",
    "    }}\n",
    "    \n",
    "    config = {{\"configurable\": {{\"thread_id\": f\"agentcore_{{random.randint(1000, 9999)}}\"}}}}\n",
    "    \n",
    "    try:\n",
    "        final_state = langgraph_workflow.invoke(initial_state, config)\n",
    "        \n",
    "        return {{\n",
    "            \"plant_type\": final_state.get('plant_detection', {{}}).get('plant_type', 'Unknown'),\n",
    "            \"health_issues\": final_state.get('health_issues', ''),\n",
    "            \"expert_advice\": final_state.get('expert_advice', ''),\n",
    "            \"recommended_fertilizer\": final_state.get('recommended_fertilizer', 'All Purpose Plant Fertilizer'),\n",
    "            \"web_search_results\": final_state.get('web_search_results', ''),\n",
    "            \"final_report\": final_state.get('final_report', ''),\n",
    "            \"memory_status\": final_state.get('memory_status', ''),\n",
    "            \"status\": \"success\"\n",
    "        }}\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Workflow error: {{str(e)}}\")\n",
    "        return {{\"error\": str(e), \"status\": \"failed\"}}\n",
    "\n",
    "print(\"âœ… Enhanced LangGraph MCP Workflow with Memory created\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ðŸš€ Starting Plant Analysis Agent...\")\n",
    "    print(f\"ðŸ”— Gateway: {{GATEWAY_ID}}\")\n",
    "    print(f\"ðŸŒ MCP URL: {{GATEWAY_URL}}\")\n",
    "    print(f\"ðŸ§  Memory ID: {{MEMORY_ID}}\")\n",
    "    print(f\"ðŸ‘¤ Actor ID: {{ACTOR_ID}}\")\n",
    "    print(f\"ðŸ“ Session ID: {{SESSION_ID}}\")\n",
    "    app.run()\n",
    "'''\n",
    "\n",
    "with open(f'{project_folder}/plant_workflow_memory.py', 'w') as f:\n",
    "    f.write(workflow_code)\n",
    "\n",
    "print(\"âœ… Workflow saved to 'plant_workflow_memory.py'\")\n",
    "print(\"ðŸ“ Remember to update the configuration values in the file!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b09360-7ad7-4f5b-88d2-5029749f0b99",
   "metadata": {},
   "source": [
    "# Deploy using Starter toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10759e4-cd12-4dea-a9b2-994283a8624e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check if Dockerfile exists and its content\n",
    "if os.path.exists('Dockerfile'):\n",
    "    with open('Dockerfile', 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"Dockerfile size: {len(content)} bytes\")\n",
    "else:\n",
    "    print(\"No Dockerfile found\")\n",
    "\n",
    "# Remove corrupted files\n",
    "for file in ['Dockerfile', '.dockerignore', '.bedrock_agentcore.yaml']:\n",
    "    if os.path.exists(file):\n",
    "        os.remove(file)\n",
    "        \n",
    "# SOLUTION: Monkey patch the prompt function to auto-answer\n",
    "import sys\n",
    "from unittest.mock import patch\n",
    "\n",
    "def mock_prompt(text, default=\"\"):\n",
    "    \"\"\"Auto-answer prompts with default values\"\"\"\n",
    "    print(f\"Auto-answering prompt: {text}\")\n",
    "    if \"memory\" in text.lower():\n",
    "        return \"no\"  # Disable long-term memory\n",
    "    return default or \"no\"\n",
    "\n",
    "# Patch the prompt function before configure\n",
    "runtime = Runtime()\n",
    "with patch('bedrock_agentcore_starter_toolkit.cli.common.prompt', side_effect=mock_prompt):\n",
    "    config = runtime.configure(\n",
    "        entrypoint=f'{project_folder}/plant_workflow_memory.py',\n",
    "        requirements_file=f'{project_folder}/requirements.txt',\n",
    "        agent_name=\"plant_advisor_agent\",\n",
    "        auto_create_ecr=True,\n",
    "        execution_role=agentcore_iam_role['Role']['Arn']\n",
    "    )\n",
    "\n",
    "# Verify Dockerfile was created properly\n",
    "if os.path.exists('Dockerfile'):\n",
    "    with open('Dockerfile', 'r') as f:\n",
    "        content = f.read()\n",
    "    print(f\"New Dockerfile size: {len(content)} bytes\")\n",
    "    if len(content) > 100:\n",
    "        print(\"âœ… Dockerfile generated successfully\")\n",
    "        runtime.launch()\n",
    "    else:\n",
    "        print(\"âŒ Dockerfile still corrupted\")\n",
    "else:\n",
    "    print(\"âŒ Dockerfile not generated\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c09985e-9b95-45d2-94b0-94653db14a04",
   "metadata": {},
   "source": [
    "# Invoke runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140e1203-7404-4d46-a47d-02a4407a6908",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path='./Image/sweet_potato_leaf.png'\n",
    "\n",
    "try:\n",
    "    print('ðŸš€ Testing Plant Agent Runtime with real image...')\n",
    "    \n",
    "    # Read and encode the image file\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "        base64_data = base64.b64encode(image_bytes).decode('utf-8')\n",
    "        print(f\"âœ… Image encoded: {len(base64_data)} characters\")\n",
    "    \n",
    "    # Test payload\n",
    "    test_payload = {\n",
    "        'prompt': 'Analyze my plant',\n",
    "        'image_data': base64_data\n",
    "    }\n",
    "    \n",
    "    response = runtime.invoke(payload=test_payload)\n",
    "    print(f'âœ… Agent invocation successful!')\n",
    "    print(f'ðŸ“ Response Content Type: {response.get(\"contentType\")}')\n",
    "    print(response)\n",
    "    \n",
    "    # Process response - FULL OUTPUT\n",
    "    if response.get(\"contentType\") == \"application/json\":\n",
    "        content = []\n",
    "        for chunk in response.get(\"response\", []):\n",
    "            #content.append(chunk.decode('utf-8'))\n",
    "            content.append(chunk)\n",
    "        result = json.loads(''.join(content))\n",
    "\n",
    "        print(response)\n",
    "        \n",
    "        print(f\"\\nðŸŒ± COMPLETE Plant Analysis Results:\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        print(f\"\\nðŸ“‹ Plant Type: {result.get('plant_type', 'Unknown')}\")\n",
    "        \n",
    "        print(f\"\\nðŸ” Health Assessment:\")\n",
    "        print(result.get('health_issues', 'None'))\n",
    "        \n",
    "        print(f\"\\nðŸ‘¨â€âš•ï¸ Expert Advice:\")\n",
    "        print(result.get('expert_advice', 'No advice available'))\n",
    "        \n",
    "        if result.get('web_search_results'):\n",
    "            print(f\"\\nðŸ” Web Search Results:\")\n",
    "            print(result.get('web_search_results'))\n",
    "        \n",
    "        print(f\"\\nðŸ“„ Final Report:\")\n",
    "        print(result.get('final_report', 'No report available'))\n",
    "        \n",
    "        print(f\"\\nâœ… Status: {result.get('status', 'Unknown')}\")\n",
    "        \n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(f\"Raw response: {response}\")\n",
    "    \n",
    "    print('\\nðŸŽ‰ Plant Agent Runtime working perfectly with real image data!')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'âŒ Agent invocation failed: {e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7012fe0-d157-493f-89c2-03cade60288f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def extract_clean_plant_analysis(response_data):\n",
    "    \"\"\"Extract clean, readable plant analysis\"\"\"\n",
    "    \n",
    "    response_bytes = response_data.get('response', [])\n",
    "    full_response = b''.join(response_bytes).decode('utf-8')\n",
    "    \n",
    "    try:\n",
    "        parsed_response = json.loads(full_response)\n",
    "        final_report = parsed_response.get('final_report', '')\n",
    "        \n",
    "        # Extract plant analysis sections\n",
    "        # Look for \"Plant: ... Health: ... Advice: ...\" patterns\n",
    "        plant_analyses = []\n",
    "        \n",
    "        # Split by numbered entries\n",
    "        entries = re.split(r'\\d+\\.\\s*{', final_report)\n",
    "        \n",
    "        for entry in entries[1:]:  # Skip the first split part\n",
    "            # Look for the text content within conversational data\n",
    "            text_matches = re.findall(r\"'text': '([^']*(?:\\\\.[^']*)*)'\", entry)\n",
    "            \n",
    "            for text in text_matches:\n",
    "                cleaned_text = text.replace('\\\\\\\\n', '\\n').replace(\"\\\\'\", \"'\")\n",
    "                \n",
    "                # Check if this looks like a plant analysis\n",
    "                if 'Plant:' in cleaned_text and 'Health:' in cleaned_text:\n",
    "                    # Split into sections\n",
    "                    sections = cleaned_text.split('\\n')\n",
    "                    \n",
    "                    plant_info = \"\"\n",
    "                    health_info = \"\"\n",
    "                    advice_info = \"\"\n",
    "                    current_section = None\n",
    "                    \n",
    "                    for line in sections:\n",
    "                        if line.startswith('Plant:'):\n",
    "                            plant_info = line\n",
    "                            current_section = 'plant'\n",
    "                        elif line.startswith('Health:'):\n",
    "                            health_info = line\n",
    "                            current_section = 'health'\n",
    "                        elif line.startswith('Advice:'):\n",
    "                            advice_info = line\n",
    "                            current_section = 'advice'\n",
    "                        elif current_section == 'health' and line.strip():\n",
    "                            health_info += \"\\n\" + line\n",
    "                        elif current_section == 'advice' and line.strip():\n",
    "                            advice_info += \"\\n\" + line\n",
    "                    \n",
    "                    if plant_info and health_info:\n",
    "                        plant_analyses.append({\n",
    "                            'plant': plant_info,\n",
    "                            'health': health_info,\n",
    "                            'advice': advice_info\n",
    "                        })\n",
    "        \n",
    "        return plant_analyses\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting analysis: {e}\")\n",
    "        return []\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "487f5560-78e2-444b-9623-a54d6f3d8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print('ðŸš€ Testing Plant Agent Runtime memory...')\n",
    "    \n",
    "    # Testing memory\n",
    "    test_payload = {\n",
    "        'prompt': \"Show me my previous plant analyses\"\n",
    "    }\n",
    "    \n",
    "    response = runtime.invoke(payload=test_payload)\n",
    "    print(f'âœ… Agent invocation successful!')\n",
    "    print(f'ðŸ“ Response Content Type: {response.get(\"contentType\")}')\n",
    "\n",
    "    # Process response - FULL OUTPUT\n",
    "    if response.get(\"contentType\") == \"application/json\":\n",
    "\n",
    "        response_data = response['response']\n",
    "        if isinstance(response_data, list) and len(response_data) > 0:\n",
    "            if isinstance(response_data[0], str):\n",
    "                # Response contains strings, join directly\n",
    "                full_response = ''.join(response_data)\n",
    "            else:\n",
    "                # Response contains bytes, decode first\n",
    "                full_response = b''.join(response_data).decode('utf-8')\n",
    "        else:\n",
    "            full_response = str(response_data)\n",
    "\n",
    "\n",
    "        \n",
    "        parsed = json.loads(full_response)\n",
    "\n",
    "        final_report= parsed.get('final_report')\n",
    "        \n",
    "        print(\"=== EXTRACTED CONTENT ===\")\n",
    "        print(f\"Status: {parsed.get('status')}\")\n",
    "        print(f\"Memory Status: {parsed.get('memory_status')}\")\n",
    "        print(f\"\\nFinal Report:\\n{final_report}\")\n",
    "\n",
    "        \n",
    "    print('\\nðŸŽ‰ Plant Agent Runtime working perfectly with memory!')\n",
    "\n",
    "except Exception as e:\n",
    "    print(f'âŒ Agent invocation failed: {e}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
